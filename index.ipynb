{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![WordCloud](./img/wordcloud.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "try:\n",
    "    username\n",
    "except NameError:\n",
    "    username = 'Lernende(r)'\n",
    "\n",
    "print('Hallo, ' + username + '!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lernmodul zur Verarbeitung und Analyse von Textdaten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Verarbeiten menschlicher Sprache gilt als Voraussetzung f√ºr eine erfolgreiche Mensch-Maschine-Kommunikation. Zus√§tzlich kann sie dabei helfen eine vom Mensch unternommene Textanalyse zu unterst√ºtzen. Handelt es sich bei diesem Kommentar um unerw√ºnschte Inhalte? Verbreitet dieser Beitrag Falschinformationen? Und welche Meinung will der Verfasser mit dieser Rezension zum Ausdruck bringen? Jene Fragestellungen lassen sich mithilfe computergest√ºtzter Methoden der Textverarbeitung und -analyse beantworten.\n",
    "\n",
    "Im folgenden Lernmodul wird versucht im Zuge einer Stimmungsanalyse (Sentiment Analysis) die Intention hinter einem Textbeitrag zu identifizieren um bspw. zwischen einer negativen und einer positiven Aussage zu unterscheiden. Diese Unterscheidung √ºbernimmt ein Modell (hier: Klassifikator), welches auf Basis von Metadaten (hier: Vokabular) eine Vorhersage (hier: Stimmung) √ºber vorliegende Rohdaten (hier: Tweets) trifft.\n",
    "\n",
    "Die folgende Abbildung verdeutlicht dabei den Weg eines Tweets, welcher die drei Dom√§nen [Daten](#daten), [Modell](#modell) und [Verwendung](#verwendung) durchl√§uft, bis er letztendlich einer Stimmung zugeordnet wurde:\n",
    "\n",
    "![Pipeline](./img/flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**√úbersicht √ºber die Lerninhalte:**\n",
    "\n",
    "1. [Einf√ºhrung](#1.-Einf√ºhrung)\n",
    "    1. [Motivation](#1.1-Motivation)\n",
    "    2. [Voraussetzungen](#1.2-Voraussetzungen)\n",
    "2. [Daten](#2.-Daten)\n",
    "    1. [Textdaten beschaffen](#2.1-Textdaten-beschaffen)\n",
    "    2. [Textdaten erkunden](#2.2-Textdaten-erkunden)\n",
    "    3. [Textdaten aufbereiten](#2.3-Textdaten-aufbereiten)\n",
    "        1. [Zeichen bereinigen](#2.3.1-Zeichen-bereinigen)\n",
    "        2. [W√∂rter bereinigen](#2.3.2-W√∂rter-bereinigen)\n",
    "        3. [Tweets bereinigen](#2.3.3-Tweets-bereinigen)\n",
    "3. [Modell](#3.-Modell)\n",
    "    1. [Textdaten einbetten](#3.1-Textdaten-einbetten)\n",
    "        1. [Vokabular](#3.1.1-Vokabular)\n",
    "        2. [Vektorisierung](#3.1.2-Vektorisierung)\n",
    "        3. [Label](#3.1.3-Label)\n",
    "        4. [Features](#3.1.4-Features)\n",
    "    2. [Textdaten klassifizieren](#3.2-Textdaten-klassifizieren)\n",
    "        1. [√úberwachte Klassifikation](#3.2.1-√úberwachte-Klassifikation)\n",
    "        2. [Un√ºberwachte Klassifikation](#3.2.2-Un√ºberwachte-Klassifikation)\n",
    "4. [Verwendung](#4.-Verwendung)\n",
    "    1. [Textdaten vorhersagen](#4.1-Textdaten-vorhersagen)\n",
    "        1. [√úberwachter Klassifikator](#4.1.1-√úberwachter-Klassifikator)\n",
    "        2. [Un√ºberwachter Klassifikator](#4.1.2-Un√ºberwachter-Klassifikator)\n",
    "5. [Abschluss](#5.-Abschluss)\n",
    "6. [Anhang](#6.-Anhang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lernziele:**\n",
    "\n",
    "Die Teilnehmer lernen in der [Datendom√§ne](#2.-Daten) Textdaten in roher Form Schritt f√ºr Schritt in kontextbezogene Daten f√ºr eine Textanalyse zu transformieren. Daraufhin bewegen sich die Teilnehmer in der [Modelldom√§ne](#3.-Modell), in der sie die Daten in das Modell einbetten um sie von zwei unterschiedlichen Algorithmen klassifizieren zu lassen. Abschlie√üend werden die entstandenen Klassifikatoren in der [Verwendungsdom√§ne](#4.-Verwendung) f√ºr eine Vorhersage der Stimmung benutzt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Voraussetzungen:**\n",
    "\n",
    "- [Python](https://www.python.org/)\n",
    "- [Lernmodul zum Datenimport und zur Datenvorbereitung mit Pandas](https://projectbase.medien.hs-duesseldorf.de/eild.nrw-module/lernmodul-pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgaben√ºberpr√ºfung:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieses Lernmodul nutzt eine Aufgaben√ºberpr√ºfung, die sich hinter der folgenden Variable verbirgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "from taskreview.learning_module import LearningModule\n",
    "lm = LearningModule('data/lernmodul_texte.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hinweis:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieses Lernmodul nutzt verschiedenste Bibliotheken, Objekte und Funktionen. Diese sollten in der vorgegebenen Reihenfolge ausgef√ºhrt werden, da ansonsten kein erfolgreicher Abschluss des Lernmoduls garantiert werden kann.\n",
    "\n",
    "Solltet ihr einmal den √úberblick verlieren, gibt euch die `whos` Funktion alle aktiven Variablen und ihre Typen (bspw. Bibliothek, Klasse) aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erweiternd dazu f√ºhrt dieses Lernmodul im [Anhang](#6.-Anhang) ein Glossar, welches englische Begriffe in ihren deutschen Kontext setzt und sie mit einem Beispiel versieht.\n",
    "\n",
    "Zudem nutzt dieses Lernmodul eine hohe Datenmenge, welche die maximal zur Verf√ºgung stehende Speicherkapazit√§t √ºberschreiten kann. Um dem vorzubeugen, k√∂nnen ungenutzte Variablen √ºber die `del` Funktion verworfen und so Speicherkapazit√§ten freigegeben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = None \n",
    "del variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #150458; padding: 5px;\"></div>\n",
    "\n",
    "## 1. Einf√ºhrung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Zur√ºck zur √úbersicht](#Lernmodul-zur-Verarbeitung-und-Analyse-von-Textdaten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Verarbeitung menschlicher Sprache (Natural Language Processing, NLP) ist ein prominentes Forschungsfeld der Informatik mit √§hnlichem Bekanntheitsgrad wie die Analyse visueller Daten (Computer Vision), welche bspw. das Erkennen von Bildern (Image Recognition) sowie ihre Manipulation (Image Augmentation) betrachtet. Im ersten Fall wollen wir einen bekannten bzw. alten Bildinhalt klassifizieren, w√§hrend der zweite Fall einen unbekannten bzw. neuen Bildinhalt erzeugt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wechseln wir von Bild- auf Textdaten, l√§sst sich das Forschungsfeld des _NLP_ auf √§hnliche Problemstellungen herunterbrechen, die in der folgenden Auflistung aufgef√ºhrt sind:\n",
    "\n",
    "* Texterkennung (Text Recognition)\n",
    "  * Spracherkennung (Speech Recognition)\n",
    "  * Stimmungsanalyse (Sentiment Analysis)\n",
    "* Textmanipulation (Text Augmentation)\n",
    "  * Maschinelle √úbersetzung (Machine Translation)\n",
    "  * Automatisches Antworten (Question Answering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieses Lernmodul besch√§ftigt sich mit der ersten Problemstellung, also der Texterkennung und im besonderen mit der Unterscheidung verschiedener Stimmungen, welche der Verfasser eines Textes gehabt haben k√∂nnte. Ein aktuelles Anwendungsbeispiel ist die Identifikation von Hassreden, wie sie bspw. von [Facebook](https://www.facebook.com/) im Zuge ihrer [Community Standards](https://www.facebook.com/communitystandards/hate_speech) verboten wurden und erkannt werden m√ºssen. Auch k√∂nnte man ein Stimmungsbild der Gesellschaft √ºber die Auswertung von Beitr√§gen auf Twitter betrachten, welches in Krisenzeiten als Entscheidungshilfe f√ºr geplante Gegenma√ünahmen dienen kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Voraussetzungen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieses Lernmodul nimmt sich [NumPy](https://numpy.org/) f√ºr numerische Berechnungen und [Pandas](https://pandas.pydata.org/) f√ºr die Verarbeitung der Daten zur Hilfe. Letztere Bibliothek konntet ihr bereits im [Lernmodul zum Datenimport und zur Datenvorbereitung mit Pandas](https://projectbase.medien.hs-duesseldorf.de/eild.nrw-module/lernmodul-pandas) kennen lernen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dazu werden die folgenden Skripte zum Verarbeiten, Modellieren & Visualisieren der Daten ben√∂tigt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import data_functions as df\n",
    "from utils import model_functions as mf\n",
    "from utils import vis_functions as vf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apropos Daten - lasst uns gleich in der [Datendom√§ne](#2.-Daten) einsteigen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #150458; padding: 5px;\"></div>\n",
    "\n",
    "## 2. Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Zur√ºck zur √úbersicht](#Lernmodul-zur-Verarbeitung-und-Analyse-von-Textdaten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Kapitel beschaffen wir uns zun√§chst einen Datensatz, welcher aus vielen Beispielen besteht, welche die Menge an Daten bildet. Ein Beispiel umfasst dabei mindestens ein, wenn nicht sogar mehrere Merkmale. Ein Merkmal wird dabei durch einen numerischen oder symbolischen Wert verk√∂rpert, der in unserem Fall ein Textbeitrag (Inhalt eines Tweets), aber auch ein Zeitstempel (Ver√∂ffentlichungsddatum eines Tweets) sein kann. \n",
    "\n",
    "Im weiteren Verlauf dieses Kapitels werden die beschafften Daten zun√§chst begutachtet und auf Basis ihrer Merkmale vorgefiltert. Daraufhin werden die √ºbrig gebliebenen Daten im Abschnitt [Textdaten aufbereiten](#2.3-Textdaten-aufbereiten) verarbeitet, um sie in der darauffolgenden [Modelldom√§ne](#3.-Modell) zu nutzen. Die Aufbereitung eines Textbeitrags l√§uft dabei exemplarisch nach folgendem Prozess ab:\n",
    "\n",
    "![Daten](./img/data_flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Textdaten beschaffen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wo findet man in der heutigen Zeit aktuelle Daten, welche eine eigene Meinung enthalten? Na auf dem Kurznachrichtendienst [Twitter](https://twitter.com) nat√ºrlich! \n",
    "\n",
    "Unser Datensatz wird dabei ungefiltert von Twitter extrahiert und monatlich unter der [CC 4.0 International](https://creativecommons.org/licenses/by/4.0/legalcode) Lizenz ver√∂ffentlicht [[1]](#1).\n",
    "\n",
    "Einen Teil dieser Ver√∂ffentlichung wollen wir zun√§chst als rohe JSON Daten unter der `twitter` Variable wie folgt abspeichern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = df.load_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Funktionalit√§t von Pandas nutzen zu k√∂nnen, wird aus jeder JSON Datei ein DataFrame, der wiederum unter der `twitter` Variable abgelegt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = map(pd.DataFrame, twitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Zusammenf√ºgen dieser resultiert in einem einzelnen DataFrame, welcher im weiteren Verlauf als Rohdatensatz fungiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = pd.concat(twitter, copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das war's auch schon mit der Beschaffung der Daten. Als n√§chstes gilt es die noch unbekannten Daten zu erkunden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Textdaten erkunden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie im [Lernmodul zum Datenimport und zur Datenvorbereitung mit Pandas](https://projectbase.medien.hs-duesseldorf.de/eild.nrw-module/lernmodul-pandas) kennengelernt, l√§sst sich √ºber die `head()` Funktion der Kopf des Datensatzes betrachten. Wie schaut dieser aus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leider liefert die `head()` Funktion nicht die Gr√∂√üe des Datensatzes zur√ºck. Wir wollen aber schlie√ülich wissen, mit wie vielen unterschiedlichen Tweets wir rechnen k√∂nnen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Wie viele Beispiele sind im `twitter` Datensatz enthalten?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(221)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Wie viele Werte liegen pro Beispiel vor? Aus wie vielen Merkmalen besteht der `twitter` Datensatz?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als erstes k√ºmmern wir uns um die Aktualit√§t der Daten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: √úber welches Merkmal k√∂nnen wir Tweets identifizieren, die nicht die gew√ºnschte Aktualit√§t besitzen?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(223)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus welchen Jahren stammen unsere Tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = vf.plot_tweets_per_year(twitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anscheinend enth√§lt unser Datensatz veraltete Tweets. Da sich unsere Fragestellung auf aktuelle Inhalte bezieht, verwerfen wir √§ltere Tweets wie folgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = twitter.loc[twitter['year'] == 2020]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als N√§chstes k√ºmmern wir uns um die Sprache, die einem jeden Tweet hinterlegt ist. Welche Sprachen sind vertreten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter['lang'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anscheinend enth√§lt unser Datensatz verschiedenste Sprachen. Da sich unsere Fragestellung auf deutsche Inhalte bezieht, verwerfen wir anderssprachige Tweets wie folgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = twitter.loc[twitter['lang'] == 'de']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach einer ersten Filterung der Daten konzentrieren wir uns zum Abschluss auf die gew√ºnschten Textbeitr√§ge. Da unser Datensatz keine relevanten Metadaten enth√§lt, extrahieren wir lediglich die Tweets vom DataFrame `twitter` in eine DataSeries `tweets` wie folgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = twitter['text']\n",
    "del twitter\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beim Extrahieren der Tweets werden ausnahmslos alle Beispiele ber√ºcksichtigt. Das gilt auch f√ºr fehlende Tweets, die in der Menge an Beispielen untergegangen sind. Sind unsere Daten nun bereit zur Aufbereitung?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Wie viele Werte fehlen im `tweets` Datensatz?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da fehlende Werte von den folgenden Schritten nicht verarbeitet werden k√∂nnen, entfernen wir sie wie folgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der √úbersicht halber f√ºgen wir ein frei erfundenes Beispiel an, um die folgenden Verarbeitungsschritte besser nachvollziehen zu k√∂nnen.\n",
    "\n",
    "> ‚ö†Ô∏è Dieser Tweet enth√§lt viele unn√ºtze Zeichen üòü die wir lieber verwerfen.\n",
    "> \n",
    "> Das wurde uns von @user unter https://example.org verraten #danke\n",
    "\n",
    "Diesen ausgedachten Tweet f√ºgen wir wie folgt an unsere Daten an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = '‚ö†Ô∏è Dieser Tweet enth√§lt viele unn√ºtze Zeichen üòü die wir lieber verwerfen. \\n Das wurde uns von @user unter https://example.org verraten! #danke'\n",
    "tweets = tweets.append(pd.Series(example), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das war's auch schon mit der Erkundung der Daten. Bis jetzt haben wir lediglich fehlende Beispiele verworfen, nicht aber vorhandene Beispiele ver√§ndert. Bevor das passiert, behalten wir lieber eine Kopie der Daten als `tweets_copy` auf die wir im Verlauf des Lernmoduls noch zur√ºckgreifen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_copy = tweets.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Wozu kann eine solche Kopie gut sein?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(225)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Textdaten aufbereiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Innerhalb der Datenaufbereitung werden wir jeden Tweet anhand seiner Bestandteile (bspw. Zeichen, W√∂rter) und Eigenschaften (bspw. L√§nge) verarbeiten. Exemplarische Verarbeitungsschritte wurden bereits zu [Anfang](#2.-Daten) dieses Kapitels visualisiert. Aber schauen wir uns erst einmal das eben angef√ºgte Beispiel an."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Mit welchem Befehl kommen wir zum letzten Tweet im `tweets` Datensatz?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(231)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leider enth√§lt unser ausgedachter Tweet allerhand Elemente, die wir gesondert behandeln m√ºssen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Zeichen bereinigen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Welche Elemente befinden sich letzten Tweet, die wir verarbeiten m√ºssen?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(232)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fangen wir mit den Emojis an. Diese werden √ºber die `process_emojis()` Funktion wie folgt verarbeitet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df.process_emojis(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Die `process_emojis()` Funktion k√ºmmert sich um ausgew√§hlte Emojis. Was passiert mit ihnen?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(233)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun k√∂nnen wir spezielle Zeichenketten, wie die URL _https://example.org_ verarbeiten. Zus√§tzlich werden √ºber die `process_strings()` Funktion Sonderzeichen wie _@_ und _\\n_ wie folgt behandelt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df.process_strings(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Die `process_strings()` Funktion k√ºmmert sich um spezielle Zeichenketten. Was passiert mit ihnen?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als letztes k√ºmmern wir uns um verbleibende Symbole (bspw. Satzzeichen) √ºber die `process_symbols()` Funktion wie folgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df.process_symbols(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Die `process_symbols()` Funktion k√ºmmert sich generell um Sonderzeichen. Was passiert mit ihnen?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 W√∂rter bereinigen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach der Bereinigung von Zeichen im vorherigen Abschnitt bleiben lediglich ganze W√∂rter √ºbrig. Jetzt k√∂nnen wir jeden Tweet in seine Bestandteile zerlegen. Dieser Schritt geht mit der Funktionsweise eines [Tokenizer](https://de.wikipedia.org/wiki/Tokenizer) einher, welcher lediglich den kompletten Tweet in einzelne Token, also W√∂rter, aufteilt. Diese lassen sich besser verarbeiten, als ein ganzer Satz.\n",
    "\n",
    "Die Zerteilung der Zeichenkette bringt uns eine Liste von W√∂rtern innerhalb eines Tweets. Dabei werden alle W√∂rter zus√§tzlich in Kleinschreibung abgebildet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.apply(str.lower).apply(str.split)\n",
    "tweets.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt besteht jeder Tweet nicht mehr nur aus einer Zeichenkette, sondern aus mehreren W√∂rtern. Aus Analysegr√ºnden fassen wir alle W√∂rter zu einer gro√üen Sammlung unter `all_words` zusammen, was die `aggregate_words()` Funktion wie folgt umsetzt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_words(tweets):\n",
    "    \"\"\"Aggregate words from tweets\"\"\"\n",
    "    \n",
    "    all_words = []\n",
    "    for sentence in tweets:\n",
    "        for word in sentence:\n",
    "            all_words.append(word)\n",
    "            \n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = aggregate_words(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Eine Sammlung aller W√∂rter findet sich in der `all_words` Liste. Wie viele unterschiedliche W√∂rter sind getweetet worden?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(236)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "all_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem wir alle W√∂rter gesammelt haben, interessieren uns die beliebtesten W√∂rter der Tweeter. An dieser Stelle greifen wir auf das Natural Language Toolkit ([NLTK](https://www.nltk.org/)) zur√ºck, welches eine H√§ufigkeitsverteilung einer Liste √ºber die `FreqDist()` Funktion wie folgt erstellt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fd = FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Die `fd` Verteilung basiert auf allen getweeteten W√∂rtern. Wie lauten die drei h√§ufigsten W√∂rter?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(237)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "fd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es ist nicht √ºberraschend, dass sich Artikel, Pronomen oder Konjunktionen als die h√§ufigsten W√∂rter entpuppen. Schauen wir also etwas genauer hin und betrachten die 30 beliebtesten W√∂rter wie folgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd.plot(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch hier scheinen Artikel, Pronomen und Konjunktionen stark vertreten zu sein. Das bringt uns zu der Frage, welchen Inhalt bzw. welche Stimmung diese W√∂rter eigentlich kommunizieren?\n",
    "\n",
    "Jene W√∂rter, werden im Kontext des _NLP_ als Stoppw√∂rter bezeichnet, da sie keine Wertung implizieren, wie es ein Adjektiv (bspw. gut, schlecht) tun w√ºrde. Stoppw√∂rter lassen sich daher √§hnlich wie das Rauschen aus einer Nachricht (hier: Tweet) entfernen, ohne dass die Information (hier: Stimmung) dieser Nachricht verloren geht.\n",
    "\n",
    "Wir werden also im folgenden Schritt alle Stoppw√∂rter entfernen. Um sie zu identifizieren, importieren wir sie √ºber die `load_stop_words()` Funktion in eine Liste `stop_words` wie folgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = df.load_stop_words()\n",
    "stop_words.Wort.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H√§tte man lediglich die meist genutzten W√∂rter aus der `fd` Verteilung genommen, w√§re man Gefahr gelaufen, relevante W√∂rter (bspw. sch√∂n), ebenfalls zu entfernen.\n",
    "\n",
    "Bevor wir alle Stoppw√∂rter aus den Tweets entfernen, fragen wir uns aber erstmal, wie viel Prozent unseres Datensatzes wir dadurch verlieren w√ºrden? Dies l√§sst sich √ºber die `stop_words_ratio()` Funktion wie folgt berechnen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_words_ratio(text):\n",
    "    \"\"\"Count stopwords in tweets\"\"\"\n",
    "    \n",
    "    stop_words_list = stop_words['Wort'].values.tolist()\n",
    "    content = [word for word in text if word not in stop_words_list]\n",
    "    \n",
    "    return 1 - len(content) / len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_ratio(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Stoppw√∂rter endg√ºltig aus unseren Tweets zu entfernen, werfen wir die `filter_tokens()` Funktion wie folgt an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tokens(tweets):\n",
    "    \"\"\"Filter tokens in tweets\"\"\"\n",
    "    \n",
    "    row_list = []\n",
    "    stop_words_list = stop_words['Wort'].values.tolist()  \n",
    "    for row in tweets:\n",
    "        \n",
    "        token_list = []\n",
    "        for token in row:\n",
    "            \n",
    "            if token not in stop_words_list:\n",
    "                if len(token) > 1:\n",
    "                    token_list.append(token)\n",
    "                    \n",
    "        row_list.append(token_list)\n",
    "    \n",
    "    return pd.Series(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = filter_tokens(tweets)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit ist unsere Sammlung von W√∂rter nicht mehr aktuell. Der Einfachheit halber sammeln wir sie erneut √ºber die `aggregate_words()` Funktion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = aggregate_words(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun k√∂nnen wir eine Aussage dar√ºber treffen, welche W√∂rter mit Ausnahme der Stoppw√∂rter am h√§ufigsten verwendet werden? Dazu lie√üe sich wiederum die `FreqDist()` Funktion nutzen. \n",
    "\n",
    "Alternativ zur bereits bekannten H√§ufigkeitsverteilung lassen sich im Kontext des _NLP_ sog. Schlagwortwolken visualisieren. An dieser Stelle greifen wir auf die [WordCloud](https://amueller.github.io/word_cloud/) Bibliothek wie folgt zur√ºck:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "wc = WordCloud()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie sehen nun die h√§ufigsten W√∂rter aus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_words = wc.generate_from_frequencies(FreqDist(all_words))\n",
    "del all_words\n",
    "vf.plot_image(most_common_words, 'Die h√§ufigsten W√∂rter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Tweets bereinigen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da uns der vergangene Abschnitt einige W√∂rter gekostet hat, wie die `stop_words_ration()` Funktion verriet, wollen wir nun verbliebenen W√∂rter pro Tweet z√§hlen. Ein Tweet, der nur noch wenige W√∂rter lang ist, verk√∂rpert keine qualitativen Daten mehr. Da Twitter kein Zeichenminimum pro Tweet setzt, kann unser Datensatz auch Tweets enthalten, die wenig bis gar keinen Inhalt repr√§sentieren. Um solche Tweets zu identifizieren berechnen wir die Wortl√§nge aller Tweets wie folgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_length = [len(tweet) for tweet in tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Die `tweets_length` Liste enth√§lt die Anzahl aller W√∂rter eines Tweet. Wie viele W√∂rter besitzt der k√ºrzeste Tweet im Datensatz?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(238)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "tweets_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoffentlich handelt es sich um einen Ausrei√üer. Das verifizieren wir wiederum mit einer H√§ufigkeitsverteilung. Dieses Mal aber als einfaches Histogramm √ºber die `plot_tweets_per_length()` Funktion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf.plot_tweets_per_length(tweets_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die meisten Tweets scheinen nach Entfernen der Stoppw√∂rter nur noch wenige W√∂rter lang zu sein. Wir behalten lediglich Tweets, die zwei oder mehr W√∂rter beinhalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets[tweets.map(len) > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zeit f√ºr ein Status Quo: wie gro√ü sind unsere Verluste nach Bereinigen von Zeichen, W√∂rtern und zu kurz geratenen Tweets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Wie viel Prozent bleiben nach Aufbereitung der Daten im Vergleich zu den urspr√ºnglichen Tweets √ºbrig?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(239)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit dem bereinigten Datensatz geht es nun weiter in die [Modelldom√§ne](#3.-Modell), in der wir uns zu aller erst um die √úberf√ºhrung der Daten in das Modell k√ºmmern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #150458; padding: 5px;\"></div>\n",
    "\n",
    "## 3. Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Zur√ºck zur √úbersicht](#Lernmodul-zur-Verarbeitung-und-Analyse-von-Textdaten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Kapitel besch√§ftigen wir uns zun√§chst mit der Klassifikation der bereinigten Daten. NLTK erm√∂glicht uns die Verwendung der folgenden Klassifikationsarten:\n",
    "\n",
    "* √úberwachte Klassifikation mittels Naive Bayes\n",
    "* Un√ºberwachte Klassifikation mittels K-means Clustering\n",
    "\n",
    "Je nach Klassifikationsart bedarf es unterschiedlicher Schritte um die Textdaten durch ein Modell klassifizieren zu lassen. Beiden Modellen ist gemein, dass sie nicht einfach mit einer Liste von W√∂rtern gef√ºttert werden k√∂nnen, wie sie aus der [Datendom√§ne](#2.-Daten) herauskommt. Daher besch√§ftigt sich der erste Abschnitt dieses Kapitels mit der √úberf√ºhrung der Daten in ein Modell. Die folgende Abbildung verdeutlicht obligatorische Schritte, die f√ºr eine √úberf√ºhrung ben√∂tigt werden: \n",
    "\n",
    "![Model](./img/model_flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Textdaten einbetten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da unsere bereinigten Daten weiterhin als Text vorliegen, ben√∂tigen wir als erstes eine √úberf√ºhrung der Daten in eine numerische Form, die von unserem Modell (hier: Klassifikator) verstanden wird. Man spricht in diesem Zusammenhang vom Einbetten ([Embedding](https://en.wikipedia.org/wiki/Word_embedding)) der W√∂rter.\n",
    "\n",
    "Es gibt unterschiedliche Verfahren, um das symbolische Wort auf einen numerischen Wert abzubilden, deren Behandlung f√ºr dieses Lernmodul aber zu weit gingen. Daher schlagen wir die W√∂rter einfach in einer Art Vokabular nach, das f√ºr jedes Wort einen eigenen Wert besitzt. Wie sieht solch ein Vokabular aus?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Vokabular "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Vokabular wurde √ºber die Universit√§t Leipzig unter der [CC BY-NC-SA 3.0 DE](https://creativecommons.org/licenses/by-nc-sa/3.0/de/) Lizenz ver√∂ffentlicht [[2]](#2) und besteht aus negativ bzw. positiv annotierten W√∂rtern der deutschen Sprache. Die Stimmungslage ist im Intervall von `[-1, 1]` bzw. `['negativ', 'positiv']` begrenzt. Schlagen wir negative W√∂rter, wie _Gefahr_ bzw. _Schuld_ im Vokabular nach, bekommen wir einen negativen Stimmungswert zur√ºckgegeben. Je positiver das Wort, desto h√∂her ist sein Stimmungswert. Neutrale W√∂rter besitzen jedoch keine Gewichtung, ihr Stimmungswert ist gleich Null.\n",
    "\n",
    "Unser Modell interessiert sich dabei lediglich f√ºr die zwei Extrema und soll als bin√§rer Klassifikator zwischen negativen und posiven Tweets differenzieren. Wir vergeben daher die Labels f√ºr unsere zwei Klassen wie folgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['negativ', 'positiv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zun√§chst holen wir uns die negativen W√∂rter f√ºr das Vokabular √ºber die `load_vocabulary()` Funktion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_vocabulary = df.load_vocabulary('negativ')\n",
    "negative_vocabulary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derselbe Weg f√ºhrt uns zum positiven Vokabular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_vocabulary = df.load_vocabulary('positiv')\n",
    "positive_vocabulary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√Ñhnlich wie beim Einlesen des `twitter` Datensatzes, f√ºhren wir das negative und das positive Vokabular im DataFrame `vocabulary` zusammen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = pd.concat([negative_vocabulary, positive_vocabulary])\n",
    "del negative_vocabulary, positive_vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie bereits f√ºr die Tweets halten wir nach fehlenden Werten Ausschau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: In welcher Spalte des Vokabulars fehlen Werte?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(311)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anstatt sie zu streichen, werden fehlende Werte mit einer leeren Zeichenkette ersetzt. Dies verhindert, dass unser Vokabular schrumpft, was wir unbedingt verhindern wollen, da unser Modell auf ein vollst√§ndiges Vokabular angewiesen ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun k√ºmmern wir uns um ein paar Versch√∂nerungen mithilfe der `format_vocabulary()` Funktion. Dabei werden insbesondere alle Deklinationsformen in eine eigene Reihe √ºberf√ºhrt und mit ihrem zugeh√∂rigen Stammwort versehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = df.format_vocabulary(vocabulary)\n",
    "vocabulary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das fertige Vokabular wollen wir nun genauer betrachten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Welche Wort-Typen sind im Vokabular vorhanden?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(312)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Wort im Vokabular verk√∂rpert entweder eine Stamm-, oder eine Deklinationsform. Letztere dienen der Verallgemeinerung des Vokabulars, da Stammformen im Text seltener vorkommen, als ihre zugeh√∂rigen Deklinationsformen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Wie viele Deklinationsformen sind im Vokabular vorhanden?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(313)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: F√§llt das Vokabular eher negativ oder eher positiv aus?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Welchen Stimmungswert besitzt das Adjektiv _gut_ im Vokabular?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(315)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Wie lautet das \"schlechteste\", also das am schlechtesten annotierte Wort im  Vokabular?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(316)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Abschluss visualisieren wir exemplarisch alle negativen Nomen mithilfe der bereits bekannten Schlagwortwolke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_negative_nouns = wc.generate_from_frequencies(df.filter_vocabulary(vocabulary, sentiment='negativ', word='NN'))\n",
    "vf.plot_image(most_negative_nouns, 'Die negativsten Nomen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bevor wir uns wieder unseren Tweets widmen, schauen wir noch auf die positiven Adjektive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_positive_adjectives = wc.generate_from_frequencies(df.filter_vocabulary(vocabulary, sentiment='positiv', word='ADJX'))\n",
    "vf.plot_image(most_positive_adjectives, 'Die positivsten Adjektive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Vektorisierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Einbetten von W√∂rtern geschieht innerhalb des _NLP_ √ºber H√§ufigkeitsverteilungen. Je √∂fter ein Wort im Text vorkommt, desto wichtiger scheint es zu sein, was sich in der Vektorisierung des Wortes widerspiegelt. In unserem Fall benutzen wir anstelle der H√§ufigkeitsverteilung das angefertigte Vokabular in der Annahme, dass je h√∂her ein Stimmungswert ausf√§llt, desto wichtiger das zugeh√∂rige Wort zu sein scheint.\n",
    "\n",
    "Daher √ºberf√ºhren wir jedes einzelne Wort eines Tweets in seinen Stimmungswert. Das Wort _gut_ kriegt dabei den Stimmungswert _0.37_ zugewiesen, wie bereits im vorherigen Abschnitt gezeigt wurde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary.loc[vocabulary['Wort'] == 'gut'].Wert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F√ºr eine performante Vektorisierung ben√∂tigen wir einen Look-up-table (LUT), welcher aus Schl√ºsselwertpaaren der Form `( Wort: Stimmungswert )` besteht und wie folgt erzeugt wird:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lut = dict((k.lower(), v) for k, v in vocabulary[['Wort', 'Wert']].values)\n",
    "list(lut.items())[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Vektorisierung wird nun √ºber die `vectorize()` Funktion erm√∂glicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(tweet):\n",
    "    \"\"\"Vectorize tweets based on look-up-table\"\"\"\n",
    "    \n",
    "    return [lut.get(word) for word in tweet if lut.get(word)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da wir die urspr√ºnglichen Textdaten behalten wollen, brauchen wir eine zus√§tzliche Spalte und damit einen DataFrame statt einer DataSeries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.to_frame(name='Token')\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Abschluss vektorisieren wir mithilfe der `vectorize()` Funktion unsere Textdaten wie folgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['Vector'] = tweets['Token'].apply(vectorize)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W√§hrend unsere Tweets lediglich als einzelne W√∂rter bzw. Vektoren vorliegen, ben√∂tigt ein √ºberwachter Klassifikator zus√§tzlich eine Klasse (hier: Label), die einem Tweet zugeordnet ist. Wie bereits bekannt wollen wir eine bin√§re Klassifikation durchf√ºhren, wonach es zwei unterschiedliche Klassen zuzuordnen gilt. \n",
    "\n",
    "Erinnern wir uns zur√ºck an die Stimmungslage im Intervall `['negativ', 'positiv']` annotiert die `label()` Funktion im folgenden jeden Tweet auf Basis seiner summierten Stimmungswerte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(tweet):\n",
    "    \"\"\"Label tweets according to sentiment score.\"\"\"\n",
    "    \n",
    "    score = sum(tweet)\n",
    "            \n",
    "    if score > 0.0:\n",
    "        return 'positiv'\n",
    "    elif score < 0.0:\n",
    "        return 'negativ'\n",
    "    else:\n",
    "        return 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['Label'] = tweets['Vector'].apply(label)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Wann bekommt ein Tweet durch die `label()` Funktion eine neutrale Stimmung zugewiesen?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(317)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neutrale Tweets sind f√ºr unsere bin√§re Klassifikation nicht relevant, da sie eine dritte Klasse verk√∂rpern. Sie werden somit verworfen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets[tweets['Label'] != 'neutral']\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun ist jedem Tweet entweder eine negative oder eine positive Stimmung zugewiesen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Wie sieht die Verteilung zwischen negativen und positiven Tweets aus? F√§llt die Stimmungslage eher negativ oder eher positiv aus?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(318)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "negative_vocabulary_count = 0\n",
    "positive_vocabulary_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Abschluss visualisieren wir das gerade erzeugte Stimmungsbild."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf.plot_pie([negative_vocabulary_count, positive_vocabulary_count], labels=labels, title='Stimmungsbild')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.4 Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unser √ºberwachter Klassifikator ist bekannterma√üen auf Features und Labels angewiesen. W√§hrend wir zweitere im vorherigen Abschnitt erzeugt haben, k√ºmmern wir uns nun um die Features eines Tweets. In diesem Fall besteht ein einzelnes Feature wiederum aus einem Schl√ºsselwertpaar der Form `{ Wort: Pr√§senz }`, das angibt, ob ein Wort in einem Tweet vorhanden ist. Da unser √ºberwachter Klassifikator alle Features gleich behandelt, ist dies f√ºr einen Tweet generell gegeben. Damit repr√§sentiert ein Tweet in unserem Fall genau so viele Features, wie er W√∂rter besitzt. \n",
    "\n",
    "Solche Single-Word-Features werden also als Schl√ºsselwertpaare √ºber die `featurize()` Funktion wie folgt zusammengestellt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(tweet):\n",
    "    \"\"\"Single word feature as key/value pair\"\"\"\n",
    "    \n",
    "    return dict([(word, True) for word in tweet])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Zusammenfassen mehrere Features √ºbernimmt die `feature_set()` Funktion. An dieser Stelle werden alle Single-Word-Features eines Tweets gesammelt und das Label (hier: Stimmung) f√ºr diesen Tweet als Tupel der Form `( Features, Label )` angehangen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_set(tweets, label):\n",
    "    \"\"\"Feature set as feature/label tuples\"\"\"\n",
    "    \n",
    "    features = tweets.loc[tweets['Label'] == label]['Token'].apply(featurize)\n",
    "    \n",
    "    return [(tweet_dict, label) for tweet_dict in features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Menge aller Feature-Sets repr√§sentiert somit die Menge aller Tweets und damit unsere Trainingsdaten f√ºr den √ºberwachten Klassifikator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = feature_set(tweets, 'negativ') + feature_set(tweets, 'positiv')\n",
    "train_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Textdaten klassifizieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie bereits behandelt wollen wir unsere Textdaten anhand zweier unterschiedlicher Modelle klassifizieren. Die folgende Abbildung verdeutlicht den Unterschied zwischen √ºberwachten und un√ºberwachten Lernen:\n",
    "\n",
    "![Image](https://datasolut.com/wp-content/uploads/2020/08/Supervised-vs-unsupervised-learning.png)\n",
    "\n",
    "W√§hrend das √ºberwachte Lernen auf unterschiedlichen Klassen (hier: Kreis und Kreuz) basiert, ben√∂tigt un√ºberwachtes Lernen keine explizite Einteilung in Klassen mithilfe von Labels. Der Vorteil liegt auf der Hand: von den vielen Schritten im vergangenen Abschnitt w√§re lediglich die Vektorisierung f√ºr eine un√ºberwachte Klassifikation notwendig gewesen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 √úberwachte Klassifikation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mithilfe des [Naive Bayes](https://www.nltk.org/_modules/nltk/classify/naivebayes.html) Algorithmus f√ºhren wir als erstes eine √ºberwachte Klassifikation aus. Dabei versucht der Klassifikator eine Menge an Features ihrer wahrscheinlichsten Klasse (hier: Stimmung) zuzuordnen. Wie im vorherigen Abschnitt behandelt wurde, repr√§sentiert jedes Wort eines Tweets ein Feature, w√§hrend der Menge aller Features (Feature-Set) die zugeh√∂rige Klasse eines Tweets angehangen ist. In der folgenden Animation wird der Lernprozess des Klassifikators auf Basis von drei Klassen und zwei Features veranschaulicht:\n",
    "\n",
    "![Naive Bayes](https://upload.wikimedia.org/wikipedia/commons/b/b4/Naive_Bayes_Classifier.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Folgenden wird der `nbclassifier` als √ºberwachter Klassifikator mithilfe von NLTK erzeugt und trainiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import NaiveBayesClassifier, classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbclassifier = NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun stellt sich die Frage, welches Feature wohl am informativsten f√ºr den Klassifikator war?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Welches Wort aus den Trainingsdaten war f√ºr den √ºberwachten Klassifikator am aussagekr√§ftigsten?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "nbclassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt wollen wir noch wissen, wie gut sich unser Klassifikator schl√§gt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Wie hoch ist die Genauigkeit des √ºberwachten Klassifikators auf den Trainingsdaten?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(322)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Un√ºberwachte Klassifikation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mithilfe von [K-means](https://www.nltk.org/_modules/nltk/cluster/kmeans.html) Clustering f√ºhren wir als zweites eine un√ºberwachte Klassifikation aus. Dabei versucht der Klassifikator √§hnliche Vektoren zu einem Cluster (hier: Stimmung) zu gruppieren. Wie bereits behandelt, wurde jedes Wort eines Tweets auf einen Stimmungswert abgebildet, wonach alle _n_ W√∂rter eines Tweets einen _n_-dimensionalen Spaltenvektor bilden. In der folgenden Animation wird der Lernprozess des Klassifikators auf Basis von drei Clustern und zwei Dimensionen veranschaulicht:\n",
    "\n",
    "![K-means](https://camo.githubusercontent.com/77a842161f9588166625169d1f0944e838837f19b105d7e55d235652cfcc3786/68747470733a2f2f692e696d6775722e636f6d2f6b3458636170492e676966)\n",
    "\n",
    "Nat√ºrlich sind nicht immer gleich viele W√∂rter pro Tweet vorhanden. Daher m√ºssen wir uns auf eine Dimensionalit√§t einigen, die vom Klassifikator ber√ºcksichtigt wird. Naheliegend entscheiden wir uns f√ºr die im Mittel gefundenen W√∂rter und verdoppeln diese Anzahl als `dimensionality` wie folgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensionality = 2 * int(np.mean([len(vector) for vector in tweets['Vector']]))\n",
    "dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun f√ºllen wir entweder fehlende Werte auf, oder schneiden zu viele Werte ab, was √ºber die `pad()` Funktion erreicht wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(tweet):\n",
    "    \"\"\"Pad vectors with zeros at the end or strip vectors based on dimensionality\"\"\"\n",
    "    \n",
    "    tweet += [0.0] * (dimensionality - len(tweet))\n",
    "    \n",
    "    return tweet[:dimensionality]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['Vector'] = tweets['Vector'].apply(pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Folgenden wird der `kmclusterer` als un√ºberwachter Klassifikator mithilfe von NLTK erzeugt..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.cluster import KMeansClusterer, euclidean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmclusterer = KMeansClusterer(2, euclidean_distance, repeats=4, avoid_empty_clusters=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...und trainiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = kmclusterer.cluster(tweets['Vector'].apply(np.array), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W√§hrend beim √ºberwachten Klassifikator die Features untersucht werden konnten, lassen sich hier lediglich die erzeugten Cluster des Klassifikators betrachten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Hinter welcher Funktion verstecken sich die Cluster unseres `kmclusterer` Klassifikators?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(323)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "centroids = [0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Abschluss schauen wir wo die Cluster liegen und ob sich ihre Lage mit dem Wertebereich der jeweiligen Stimmungswerte deckt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf.plot_clusters(centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #150458; padding: 5px;\"></div>\n",
    "\n",
    "## 4. Verwendung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Zur√ºck zur √úbersicht](#Lernmodul-zur-Verarbeitung-und-Analyse-von-Textdaten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Kapitel werden zum Abschluss eigene Tweets vorhergesagt, sowie bestehende Tweets f√ºr eine exemplarische Untersuchung der Vorhersagegenauigkeit verwendet.\n",
    "\n",
    "Je nach Klassifikator sind daf√ºr verschiedene Schritte n√∂tig, die bereits aus den vorherigen Kapiteln bekannt sind und die in der folgenden Abbildung verdeutlicht werden:\n",
    "\n",
    "![Usage](./img/usage_flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Textdaten vorhersagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplarisch wird ein frei erfundener negativer Tweet betrachtet:\n",
    "\n",
    "> Was f√ºr EiN schlechtes Lernmodul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_tweet = \"Was f√ºr EiN schlechtes Lernmodul\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ebenfalls wird ein positives Beispiel betrachtet:\n",
    "\n",
    "> Was f√ºr EiN gutes Lernmodul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tweet = \"Was f√ºr EiN gutes Lernmodul\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional kann ein eigener Tweet hier eingegeben werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tweet = input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im produktiven Einsatz m√ºssten all diese Beispiele in der Datendom√§ne aufbereitet werden, was wir uns in diesem Fall aber ersparen und lieber auf bereits aufbereitete Tweets zur√ºckgreifen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets.merge(tweets_copy.to_frame(name='Text'), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun w√§hlen wir 100 zuf√§llige Exemplare wie folgt aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tweets = tweets.sample(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einzelne zuf√§llige Tweets finden sich folgenderma√üen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['Text'].sample(1).values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 √úberwachter Klassifikator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um den √ºberwachten Klassifikator f√ºr eine Vorhersage zu nutzen, wird die folgende Funktion zur Hilfe genommen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_supervised(tweet, classifier):\n",
    "    print('Tweet:', tweet, '\\nStimmung:', classifier.classify(featurize(str.split(str.lower(tweet)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welche Stimmung dr√ºckt unser negatives Beispiel nach Vorhersage der √ºberwachten Klassifikation aus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_supervised(negative_tweet, nbclassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welche Stimmung dr√ºckt unser positives Beispiel nach Vorhersage der √ºberwachten Klassifikation aus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_supervised(positive_tweet, nbclassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welche Stimmung dr√ºckt unser selbst gew√§hltes Beispiel nach Vorhersage der √ºberwachten Klassifikation aus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_supervised(user_tweet, nbclassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie schl√§gt sich unser √ºberwachter Klassifikator im Detail? Daf√ºr klassifizieren wir beispielhaft 100 Tweets √ºber die `classify_supervised_multiple()` Funktion. Falsche Vorhersagen lassen sich √ºber die Spalte _Prognose_ identifizieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.classify_supervised_multiple(sample_tweets, nbclassifier, labels) # On Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 Un√ºberwachter Klassifikator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um den un√ºberwachten Klassifikator f√ºr eine Vorhersage zu nutzen, wird die folgende Funktion zur Hilfe genommen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_unsupervised(tweet, classifier):\n",
    "    print('Tweet:', tweet, '\\nStimmung:', labels[kmclusterer.classify(pad(vectorize(str.split(str.lower(tweet)))))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welche Stimmung dr√ºckt unser negatives Beispiel nach Vorhersage der un√ºberwachten Klassifikation aus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_unsupervised(negative_tweet, kmclusterer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welche Stimmung dr√ºckt unser positives Beispiel nach Vorhersage der un√ºberwachten Klassifizierung aus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_unsupervised(positive_tweet, kmclusterer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welche Stimmung dr√ºckt unser selbst gew√§hltes Beispiel nach Vorhersage der un√ºberwachten Klassifikation aus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_unsupervised(user_tweet, kmclusterer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie schl√§gt sich unser un√ºberwachter Klassifikator im Detail? Daf√ºr klassifizieren 100 zuf√§llig ausgew√§hlte Tweets √ºber die `classify_unsupervised_multiple()` Funktion. Falsche Vorhersagen lassen sich √ºber die Spalte _Prognose_ identifizieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.classify_unsupervised_multiple(sample_tweets, kmclusterer, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #150458; padding: 5px;\"></div>\n",
    "\n",
    "## 5. Abschluss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Zur√ºck zur √úbersicht](#Lernmodul-zur-Verarbeitung-und-Analyse-von-Textdaten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Abschluss des Lernmoduls folgen einige Verst√§ndnisfragen, bevor deine Gesamtpunktzahl errechnet wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Welche Eingabe(n) ben√∂tigt der √ºberwachte Klassifikator?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.show_task(501)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Welche Eingabe(n) ben√∂tigt der un√ºberwachte Klassifikator?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.show_task(502)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Das Vokabular wird in diesem Lernmodul daf√ºr verwendet...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.show_task(503)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Welche Faktoren haben einen direkten Einfluss auf die Trainingsdauer des un√ºberwachten Klassifikators?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.show_task(504)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Du hast es geschafft. Gl√ºckwunsch!\n",
    "\n",
    "![Applause](https://media.giphy.com/media/FnGdcQzqypBaE/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ergebnis:**\n",
    "\n",
    "Du hast folgende Punktzahl erreicht..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.get_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submitButton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zusammenfassung:**\n",
    "\n",
    "Das vergangene Lernmodul gab einen Einblick in die Texterkennung als Teilgebiet des _NLP_. Im Zuge einer Stimmungsanalyse von aktuellen Beitr√§gen auf Twitter, haben wir in der [Datendom√§ne](#2.-Daten) zun√§chst Rohdaten beschafft und erkundet. Irrelevante Inhalte wurden auf Basis von Sonderzeichen, Stoppw√∂rtern und der L√§nge des resultierenden Beitrags, identifiziert und verworfen. Daraufhin wurden die Daten in der [Modelldom√§ne](#3.-Modell) entweder √ºberwacht oder un√ºberwacht klassifiziert, wobei verschiedene Einbettungsschritte, wie das Vektorisieren oder das Annotieren der Textdaten vorausgingen. Letztendlich konnte in der [Verwendungsdom√§ne](#4.-Verwendung) sowohl der √ºberwachte als auch der un√ºberwachte Klassifikator die Stimmung eines Tweets korerkt vorhersagen. Jene Vorhersage lie√üe sich mithilfe alternativer Modelle, wie sie bspw. im [Lernmodul zu Datamining mit Scikit Learn](https://projectbase.medien.hs-duesseldorf.de/eild.nrw-module/lernmodul-scikit) behandelt werden, verbessern. Analog dazu k√∂nnen Schritte, wie der Tokenizer, oder das Embedding, unabh√§ngig vom Modell optimiert werden. Weiterf√ºhrendes Material dazu befindet sich im [Anhang](#6.-Anhang)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #150458; padding: 5px;\"></div>\n",
    "\n",
    "## 6. Anhang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Zur√ºck zur √úbersicht](#Lernmodul-zur-Verarbeitung-und-Analyse-von-Textdaten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.giphy.com/media/l2Je66zG6mAAZxgqI/giphy.gif\" alt=\"Vokabular\" style=\"width: 256px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Glossar:**\n",
    "\n",
    "* Embedding\n",
    "    * Einbetten von W√∂rtern in Modell (hier: Klassifikator)\n",
    "* Label\n",
    "    * Klasse (hier: Stimmung)\n",
    "* Look-up-table\n",
    "    * Schl√ºsselwertpaar (hier: Vokabular)\n",
    "* NLP (Natural Language Processing)\n",
    "    * Verarbeitung menschlicher Sprache\n",
    "* NLTK (Natural Language ToolKit)\n",
    "    * Python-Bibliothek f√ºr die Verarbeitung menschlicher Sprache\n",
    "* Token\n",
    "    * Ein oder mehrere W√∂rter (hier: Monogramme)\n",
    "* Tokenization\n",
    "    * Zerteilung von S√§tzen in ein oder mehrere W√∂rter (hier: Monogramme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weiterf√ºhrende Lernmodule:**\n",
    "\n",
    "- [Lernmodul zu Datamining mit Scikit Learn](https://projectbase.medien.hs-duesseldorf.de/eild.nrw-module/lernmodul-scikit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weiterf√ºhrende Inhalte:**\n",
    "\n",
    "* Leitf√§den\n",
    "    * [Cookbook by NLTK](https://www.nltk.org/book/)\n",
    "    * [Recurrent neural networks by TensorFlow](https://www.tensorflow.org/guide/keras/rnn?hl=en)\n",
    "    * [Text classification by Google Developers](https://developers.google.com/machine-learning/guides/text-classification)\n",
    "* Embedding\n",
    "    * [TextBlob](https://textblob.readthedocs.io/en/dev/)\n",
    "    * [Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html)\n",
    "* Tutorials\n",
    "    * [Basic text classification by TensorFlow](https://www.tensorflow.org/tutorials/keras/text_classification?hl=en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referenzen:**\n",
    "\n",
    "<a id=\"1\">[1]</a> Nane Kratzke. (2020). Monthly Samples of German Tweets (Version 2020-04) [Data set]. Zenodo. http://doi.org/10.5281/zenodo.3783478\n",
    "\n",
    "<a id=\"2\">[2]</a> R. Remus, U. Quasthoff & G. Heyer: SentiWS - a Publicly Available German-language Resource for Sentiment Analysis. In: Proceedings of the 7th International Language Resources and Evaluation (LREC'10), pp. 1168-1171, 2010"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
